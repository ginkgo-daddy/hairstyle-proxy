#!/usr/bin/env python3
"""
æ£€æŸ¥ç°æœ‰ç¼“å­˜çŠ¶æ€
æ˜¾ç¤ºå·²ç¼“å­˜çš„å›¾ç‰‡ä¿¡æ¯å’Œç»Ÿè®¡
"""

import os
import json
from datetime import datetime
from pathlib import Path

def format_file_size(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if size_bytes == 0:
        return "0B"
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    return f"{size_bytes:.1f}{size_names[i]}"

def check_cache_status(output_base_dir="outputs"):
    """æ£€æŸ¥ç¼“å­˜çŠ¶æ€"""
    print("ç¼“å­˜çŠ¶æ€æ£€æŸ¥")
    print("="*80)
    
    total_cached_files = 0
    total_cache_size = 0
    
    for image_type in ['user', 'hairstyle']:
        cache_dir = os.path.join(output_base_dir, f"gemini_processed_{image_type}")
        cache_index_path = os.path.join(cache_dir, "cache_index.json")
        
        print(f"\nğŸ“ {image_type.upper()} å›¾ç‰‡ç¼“å­˜çŠ¶æ€:")
        print("-" * 60)
        
        if not os.path.exists(cache_dir):
            print(f"âŒ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: {cache_dir}")
            continue
        
        if not os.path.exists(cache_index_path):
            print(f"âŒ ç¼“å­˜ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {cache_index_path}")
            continue
        
        try:
            # è¯»å–ç¼“å­˜ç´¢å¼•
            with open(cache_index_path, 'r', encoding='utf-8') as f:
                cache_index = json.load(f)
            
            if not cache_index:
                print(f"ğŸ“ ç¼“å­˜ç´¢å¼•ä¸ºç©º")
                continue
            
            print(f"ğŸ“Š ç´¢å¼•ä¸­è®°å½•çš„æ–‡ä»¶æ•°: {len(cache_index)}")
            
            # æ£€æŸ¥å®é™…æ–‡ä»¶å­˜åœ¨æƒ…å†µ
            valid_files = 0
            invalid_files = 0
            type_cache_size = 0
            
            print(f"\nğŸ“‹ ç¼“å­˜æ–‡ä»¶è¯¦æƒ…:")
            print(f"{'åºå·':<4} {'åŸå§‹æ–‡ä»¶å':<30} {'çŠ¶æ€':<6} {'å¤§å°':<10} {'æ—¶é—´':<20}")
            print("-" * 80)
            
            for i, (file_hash, info) in enumerate(cache_index.items(), 1):
                original_filename = info.get('original_filename', 'Unknown')
                processed_path = info.get('processed_path', '')
                timestamp = info.get('timestamp', '')
                
                # æ ¼å¼åŒ–æ—¶é—´æˆ³
                try:
                    if timestamp:
                        dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                        time_str = dt.strftime('%m-%d %H:%M')
                    else:
                        time_str = 'Unknown'
                except:
                    time_str = 'Invalid'
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if os.path.exists(processed_path):
                    file_size = os.path.getsize(processed_path)
                    size_str = format_file_size(file_size)
                    status = "âœ…"
                    valid_files += 1
                    type_cache_size += file_size
                else:
                    size_str = "N/A"
                    status = "âŒ"
                    invalid_files += 1
                
                # æˆªæ–­æ–‡ä»¶åå¦‚æœå¤ªé•¿
                display_name = original_filename[:28] + ".." if len(original_filename) > 30 else original_filename
                
                print(f"{i:<4} {display_name:<30} {status:<6} {size_str:<10} {time_str:<20}")
                
                # åªæ˜¾ç¤ºå‰10ä¸ªæ–‡ä»¶çš„è¯¦æƒ…ï¼Œé¿å…è¾“å‡ºå¤ªé•¿
                if i >= 10:
                    remaining = len(cache_index) - 10
                    if remaining > 0:
                        print(f"... è¿˜æœ‰ {remaining} ä¸ªæ–‡ä»¶ ...")
                    break
            
            print("-" * 80)
            print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
            print(f"  æœ‰æ•ˆç¼“å­˜æ–‡ä»¶: {valid_files}")
            print(f"  æ— æ•ˆç¼“å­˜æ–‡ä»¶: {invalid_files}")
            print(f"  ç¼“å­˜æ€»å¤§å°: {format_file_size(type_cache_size)}")
            
            total_cached_files += valid_files
            total_cache_size += type_cache_size
            
        except Exception as e:
            print(f"âŒ è¯»å–ç¼“å­˜ç´¢å¼•å¤±è´¥: {e}")
    
    # æ€»ä½“ç»Ÿè®¡
    print("\n" + "="*80)
    print("ğŸ“Š æ€»ä½“ç¼“å­˜ç»Ÿè®¡:")
    print(f"  æ€»ç¼“å­˜æ–‡ä»¶æ•°: {total_cached_files}")
    print(f"  æ€»ç¼“å­˜å¤§å°: {format_file_size(total_cache_size)}")
    print("="*80)
    
    return total_cached_files > 0

def check_directory_cache_coverage(base_directories, output_base_dir="outputs"):
    """æ£€æŸ¥ç›®å½•çš„ç¼“å­˜è¦†ç›–æƒ…å†µ"""
    print("\nğŸ” ç¼“å­˜è¦†ç›–æƒ…å†µåˆ†æ:")
    print("="*80)
    
    from batch_gemini_processor import BatchGeminiProcessor
    
    # åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„å¤„ç†å™¨æ¥ä½¿ç”¨å…¶æ–¹æ³•
    class SimpleCacheChecker:
        def __init__(self, output_base_dir):
            self.output_base_dir = output_base_dir
        
        def get_file_hash(self, file_path):
            import hashlib
            hash_md5 = hashlib.md5()
            try:
                with open(file_path, "rb") as f:
                    for chunk in iter(lambda: f.read(4096), b""):
                        hash_md5.update(chunk)
                return hash_md5.hexdigest()
            except:
                return None
        
        def determine_image_type(self, image_path):
            path_lower = image_path.lower()
            if '/user/' in path_lower or '\\user\\' in path_lower:
                return 'user'
            elif '/hairstyle/' in path_lower or '\\hairstyle\\' in path_lower:
                return 'hairstyle'
            elif '/hairstyle2/' in path_lower or '\\hairstyle2\\' in path_lower:
                return 'hairstyle'
            else:
                if 'user' in path_lower:
                    return 'user'
                elif 'hairstyle' in path_lower or 'hair' in path_lower:
                    return 'hairstyle'
                else:
                    if '/man/' in path_lower or '/woman/' in path_lower:
                        return 'hairstyle'
                    else:
                        return 'user'
        
        def find_image_files(self, directory):
            image_extensions = {'.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG'}
            image_files = []
            for root, dirs, files in os.walk(directory):
                for file in files:
                    if any(file.endswith(ext) for ext in image_extensions):
                        image_files.append(os.path.join(root, file))
            return image_files
        
        def get_cached_processed_path(self, original_path, image_type):
            try:
                file_hash = self.get_file_hash(original_path)
                if not file_hash:
                    return None
                
                cache_dir = os.path.join(self.output_base_dir, f"gemini_processed_{image_type}")
                cache_index_path = os.path.join(cache_dir, "cache_index.json")
                
                if not os.path.exists(cache_index_path):
                    return None
                
                try:
                    with open(cache_index_path, 'r', encoding='utf-8') as f:
                        cache_index = json.load(f)
                except:
                    return None
                
                if file_hash in cache_index:
                    cached_info = cache_index[file_hash]
                    cached_path = cached_info["processed_path"]
                    
                    if os.path.exists(cached_path):
                        return cached_path
                
                return None
            except:
                return None
    
    checker = SimpleCacheChecker(output_base_dir)
    
    for directory in base_directories:
        if not os.path.exists(directory):
            continue
        
        print(f"\nğŸ“‚ ç›®å½•: {directory}")
        image_files = checker.find_image_files(directory)
        
        if not image_files:
            print("  ğŸ“ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            continue
        
        # ç»Ÿè®¡ç¼“å­˜æƒ…å†µ
        cached_count = {'user': 0, 'hairstyle': 0}
        total_count = {'user': 0, 'hairstyle': 0}
        
        for image_file in image_files:
            image_type = checker.determine_image_type(image_file)
            total_count[image_type] += 1
            
            cached_path = checker.get_cached_processed_path(image_file, image_type)
            if cached_path:
                cached_count[image_type] += 1
        
        print(f"  ğŸ“Š ç»Ÿè®¡:")
        for img_type in ['user', 'hairstyle']:
            total = total_count[img_type]
            cached = cached_count[img_type]
            if total > 0:
                percentage = (cached / total) * 100
                print(f"    {img_type}: {cached}/{total} ({percentage:.1f}%) å·²ç¼“å­˜")

def main():
    """ä¸»å‡½æ•°"""
    output_base_dir = "outputs"
    
    # æ£€æŸ¥åŸºæœ¬ç¼“å­˜çŠ¶æ€
    has_cache = check_cache_status(output_base_dir)
    
    if has_cache:
        # å¦‚æœæœ‰ç¼“å­˜ï¼Œæ£€æŸ¥è¦†ç›–æƒ…å†µ
        base_directories = [
            "/Users/alex_wu/work/hair/man",
            "/Users/alex_wu/work/hair/woman"
        ]
        check_directory_cache_coverage(base_directories, output_base_dir)
    else:
        print("\nğŸ’¡ æç¤º: å½“å‰æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç¼“å­˜æ–‡ä»¶")
        print("   è¿è¡Œ batch_gemini_processor.py å¼€å§‹å¤„ç†å›¾ç‰‡")

if __name__ == "__main__":
    main()
